{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install openai\n",
        "pip install git+https://github.com/openai/swarm.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE-socjyCfNa"
      },
      "source": [
        "# Linkedin Agent Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "FuLdhcYoF6_H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import json\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"Rapid_API_Key\"] = userdata.get('Rapid_API')\n",
        "os.environ[\"Email_password\"] = userdata.get('Email_Password')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KUDANK7NuPIQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def profile_info(linkedin_url):\n",
        "    querystring = {\"url\": linkedin_url}\n",
        "    Rapid_API=userdata.get('Rapid_API')\n",
        "    headers = {\n",
        "        \"x-rapidapi-key\": Rapid_API,\n",
        "        \"x-rapidapi-host\": \"linkedin-data-api.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    print(\"LinkedIn Agent called......\")\n",
        "\n",
        "    # Making the request\n",
        "    try:\n",
        "        response = requests.get(\n",
        "            \"https://linkedin-data-api.p.rapidapi.com/get-profile-data-by-url\",\n",
        "            headers=headers,\n",
        "            params=querystring\n",
        "        )\n",
        "\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        # Try to parse the response as JSON\n",
        "        data = response.json()\n",
        "\n",
        "        # Fetch the last LinkedIn post\n",
        "        last_linkedin_post = last_post(data['username'])\n",
        "\n",
        "        # Prepare profile data\n",
        "        profile_data = {\n",
        "            \"firstName\": data.get('firstName', 'N/A'),\n",
        "            \"lastName\": data.get('lastName', 'N/A'),\n",
        "            \"job_title\": data.get('fullPositions', [{}])[0].get('title', 'N/A'),\n",
        "            \"job_company\": data.get('fullPositions', [{}])[0].get('companyName', 'N/A'),\n",
        "            \"last_linkedin_post\": last_linkedin_post,\n",
        "        }\n",
        "\n",
        "        print(profile_data)\n",
        "        return profile_data\n",
        "\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        print(f\"HTTP error occurred: {http_err}\")\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        print(f\"Request error occurred: {req_err}\")\n",
        "    except ValueError:  # This catches JSON decoding errors\n",
        "        print(\"Error: Unable to decode JSON from response.\")\n",
        "        print(\"Response Text:\", response.text)\n",
        "    except KeyError as key_err:\n",
        "        print(f\"KeyError: {key_err}. Missing expected data in the response.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "# Get profile's last post\n",
        "def last_post(linkedin_username):\n",
        "    print(\"Retreiving Last linkedin Post\")\n",
        "    querystring = {\"username\": linkedin_username}\n",
        "    url = \"https://linkedin-data-api.p.rapidapi.com/get-profile-posts\"\n",
        "    Rapid_API=userdata.get('Rapid_API')\n",
        "\n",
        "    headers = {\n",
        "        \"x-rapidapi-key\": Rapid_API,\n",
        "        \"x-rapidapi-host\": \"linkedin-data-api.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=querystring)\n",
        "        response.raise_for_status()  # Ensure the request was successful\n",
        "\n",
        "        # Parse the response JSON\n",
        "        data = response.json()\n",
        "\n",
        "        data=data['data']\n",
        "        # Get the last post if available\n",
        "\n",
        "        last_post = data[0].get('text', 'No content available')\n",
        "\n",
        "\n",
        "        print(last_post)\n",
        "        return last_post\n",
        "\n",
        "    except requests.exceptions.RequestException as req_err:\n",
        "        print(f\"Request error occurred: {req_err}\")\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to decode JSON from response.\")\n",
        "        print(\"Response Text:\", response.text)\n",
        "    except KeyError as key_err:\n",
        "        print(f\"KeyError: {key_err}. Missing expected data in the response.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return \"Error retrieving last post\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW0HbdoECaoV"
      },
      "source": [
        "# SEO Agent Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LiDZ0h832joF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "def get_SEO_data(website_url):\n",
        "    print(\"SEO Agent called......\")\n",
        "\n",
        "    # Securely load API key from environment variables\n",
        "    Rapid_API=userdata.get('Rapid_API')\n",
        "    headers = {\n",
        "        \"x-rapidapi-key\": Rapid_API,\n",
        "        \"x-rapidapi-host\": \"ahrefs2.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        ### Traffic Info\n",
        "        url_traffic = \"https://ahrefs2.p.rapidapi.com/traffic\"\n",
        "        querystring = {\"url\": website_url, \"mode\": \"subdomains\"}\n",
        "        response_traffic = requests.get(url_traffic, headers=headers, params=querystring)\n",
        "        response_traffic.raise_for_status()  # Raise an exception for bad responses\n",
        "        traffic_data = response_traffic.json()\n",
        "\n",
        "        ### Website Info\n",
        "        url_authority = \"https://ahrefs2.p.rapidapi.com/authority\"\n",
        "        response_website = requests.get(url_authority, headers=headers, params=querystring)\n",
        "        response_website.raise_for_status()\n",
        "        website_data = response_website.json()\n",
        "\n",
        "        ### Extracting data for the report\n",
        "        seo_params = {\n",
        "            \"traffic_history\": (\n",
        "                f\"For date {traffic_data['traffic_history'][4]['date']}: \"\n",
        "                f\"organic traffic was {traffic_data['traffic_history'][4]['organic']}, and \"\n",
        "                f\"for date {traffic_data['traffic_history'][5]['date']}: \"\n",
        "                f\"organic traffic was {traffic_data['traffic_history'][5]['organic']}\"\n",
        "            ),\n",
        "            \"website_data\": (\n",
        "                f\"Domain Rating: {website_data['domainRating']}, \"\n",
        "                f\"URL Rating: {website_data['urlRating']}, \"\n",
        "                f\"Backlinks: {website_data['backlinks']}, \"\n",
        "                f\"Referring Domains: {website_data['refdomains']}, \"\n",
        "                f\"Dofollow Backlinks: {website_data['dofollowBacklinks']}, \"\n",
        "                f\"Dofollow Referring Domains: {website_data['dofollowRefdomains']}\"\n",
        "            )\n",
        "        }\n",
        "        print(seo_params)\n",
        "        # Generate SEO report using OpenAI\n",
        "        seo_report = get_SEO_report(seo_params)\n",
        "        return seo_report\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def get_SEO_report(seo_params):\n",
        "    client = openai.OpenAI()  # Ensure proper OpenAI client initialization\n",
        "    prompt = f\"\"\"\n",
        "    ### Role:\n",
        "    You are an SEO Specialist.\n",
        "\n",
        "    ### Task:\n",
        "    Analyze the provided SEO data to uncover actionable insights that can enhance the website’s organic ranking.\n",
        "\n",
        "    ### Context:\n",
        "    You have access to traffic history, domain rating, URL rating, total backlinks, referring domains, and dofollow backlinks.\n",
        "    Your goal is to evaluate these data points, identify patterns, and provide recommendations to improve the site’s organic visibility and overall SEO performance.\n",
        "\n",
        "    ### Specific Instructions:\n",
        "    - **Traffic History**:\n",
        "      - Examine traffic trends over time, focusing on fluctuations between specific dates.\n",
        "        Highlight any significant drops or spikes in organic traffic, pinpoint potential causes (e.g., algorithm updates, technical issues), and suggest corrective actions.\n",
        "\n",
        "    - **Domain and URL Rating**:\n",
        "      - Compare the domain rating and URL rating against competitors to evaluate the site’s authority.\n",
        "        Identify areas to enhance authority through improved content quality, link-building strategies, or technical SEO optimizations.\n",
        "\n",
        "    - **Backlink Profile**:\n",
        "      - Assess the site’s backlink profile, including the total number of backlinks, referring domains, dofollow backlinks, and dofollow referring domains.\n",
        "        Highlight strengths and weaknesses, and recommend strategies to acquire high-quality backlinks that could boost the site’s authority and rankings.\n",
        "\n",
        "    ### Deliverables:\n",
        "    - A comprehensive analysis of the site’s SEO performance, identifying key opportunities for improvement.\n",
        "    - Actionable recommendations for enhancing organic search visibility and overall SEO health.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Here is the required SEO data for generating SEO report: {seo_params}\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Access the content directly from the message object\n",
        "    print(response.choices[0].message.content)\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36Oq9bGgGZJV"
      },
      "source": [
        "# Email Composer Agent Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "D0kH6mYcRcKx"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "def compose_email_body(seo_report, linkedin_data):\n",
        "    print(\"Email Writing Agent called\")\n",
        "    client = openai.OpenAI()\n",
        "    # Initialize OpenAI API client\n",
        "    openai.api_key = \"your_openai_api_key\"  # Ensure to replace with your actual API key\n",
        "\n",
        "    # Compose the prompt with proper variable references\n",
        "    prompt = f\"\"\"\n",
        "    # Role:\n",
        "    You are an experienced SEO specialist representing Webbografi. Your goal is to engage with a lead candidate from LinkedIn,\n",
        "    you have access to their LinkedIn profile information: {linkedin_data}.\n",
        "    You have access to an SEO report that highlights performance metrics and issues on their website: {seo_report}.\n",
        "\n",
        "    # Task:\n",
        "    Compose a brief yet personalized outreach email body, offering a complimentary SEO audit tailored to their website's needs.\n",
        "    The audit will identify current issues and provide actionable steps to enhance search rankings, website performance, and user experience.\n",
        "\n",
        "    ## Steps:\n",
        "    1. Personalized Introduction:\n",
        "        Start by addressing the lead's first name and reference a recent LinkedIn post to show familiarity with their work: use the following information : {linkedin_data}.\n",
        "\n",
        "        Connect their post to the potential benefits of improving their website’s SEO.\n",
        "\n",
        "    2. Problem Statement:\n",
        "        Mention key areas of concern on their website based on the insights from the SEO report {seo_report}.\n",
        "\n",
        "    3. Solution Offering:\n",
        "        Describe how Webbografi's free SEO audit will uncover and diagnose these issues in detail, along with a step-by-step plan to resolve them.\n",
        "        Highlight the audit’s value in improving their search engine rankings and overall website performance.\n",
        "\n",
        "    # Specifics:\n",
        "    Keep the email body concise, focusing on the key problem areas briefly. Make the offer clear and actionable.dont addsubject line\n",
        "    \"\"\"\n",
        "\n",
        "    # Call the OpenAI API\n",
        "    response =  client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"You are a helpful assistant skilled at writing professional cold emails.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Access the content directly from the message object\n",
        "    print(response.choices[0].message.content)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "BzOAITavue3t"
      },
      "outputs": [],
      "source": [
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "def send_email(receiver_email,body):\n",
        "\n",
        "\n",
        "    client = openai.OpenAI()\n",
        "    response =  client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Generate a subject content  for an email based on the following body: {body}\"\n",
        "\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "    subject=response.choices[0].message.content\n",
        "    # Email configuration\n",
        "    sender_email = \"sasmitshashwat@gmail.com\"\n",
        "\n",
        "    password = userdata.get('Email_Password')\n",
        "\n",
        "\n",
        "\n",
        "    # Set up the MIME\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] =sender_email\n",
        "    msg['To'] = receiver_email\n",
        "    msg['Subject'] = subject\n",
        "\n",
        "    # Attach body to the email\n",
        "    msg.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "    try:\n",
        "        # Server setup (for Gmail; change if using a different provider)\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()  # Secure the connection\n",
        "        server.login(sender_email, password)\n",
        "\n",
        "        # Send the email\n",
        "        text = msg.as_string()\n",
        "        server.sendmail(sender_email, receiver_email, text)\n",
        "        server.quit()\n",
        "\n",
        "        print(\"Email sent successfully!\")\n",
        "        return \"Email sent successfully!\"\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to send email: {str(e)}\")\n",
        "        return f\"Failed to send email: {str(e)}\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byRz71LKs1qN"
      },
      "source": [
        "# Defining Agents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "fOYrKpVis3tR"
      },
      "outputs": [],
      "source": [
        "from swarm import Agent\n",
        "\n",
        "\n",
        "# Function to transfer to SEO Agent\n",
        "def transfer_to_SEO_Agent(website_url):\n",
        "    \"\"\"Hand off the website url for generating SEO report.\"\"\"\n",
        "    return SEO_agent\n",
        "\n",
        "# Function to transfer to LinkedIn Agent\n",
        "def transfer_to_Linkedin_Agent(linkedin_url):\n",
        "    \"\"\"Hand off the LinkedIn URL to get profile info.\"\"\"\n",
        "    return linkedin_agent\n",
        "\n",
        "def transfer_to_Email_writing_Agent():\n",
        "    \"\"\"Hand off the data for composing the email\"\"\"\n",
        "    return Email_writing_agent\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "linkedin_agent = Agent(\n",
        "    name=\"Linkedin Agent\",\n",
        "    instructions=\"You are a helpful agent whose job is to fetch information from the LinkedIn profile of a person using their profile url\",\n",
        "    functions=[profile_info,transfer_to_SEO_Agent,],\n",
        ")\n",
        "\n",
        "SEO_agent=Agent(\n",
        "    name=\"SEO Agent\",\n",
        "    instructions=\"you are a smart agent which provides SEO report for a website\",\n",
        "    functions=[get_SEO_data,transfer_to_Email_writing_Agent],\n",
        ")\n",
        "Email_writing_agent=Agent(\n",
        "    name=\"Email Writing Agent\",\n",
        "    instructions=\"You are a smart agent tasked with composing and sending a cold email to a client offering a free SEO audit for their website. To make the email feel more personal and engaging, you use insights gathered from their LinkedIn profile.\",\n",
        "    functions=[compose_email_body,send_email],\n",
        ")\n",
        "\n",
        "\n",
        "user_interface_agent = Agent(\n",
        "    name=\"User Interface Agent\",\n",
        "    instructions=\"You are a user interface agent that handles all interactions with the user. You need to always start with a objective for writing cold emails  for leads using their website URL and their linkedin-URL . Be concise.\",\n",
        "    functions=[transfer_to_Linkedin_Agent],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzNY9Bgx0LjI"
      },
      "source": [
        "# Start Streaming\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Eh9v4V0K5y",
        "outputId": "d3aa34fe-1ec9-4341-eb83-6f3f5853f84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Swarm CLI 🐝\n",
            "\u001b[90mUser\u001b[0m: write a cold email email:sasmitshashwat@outlook.com website url:https://garyvaynerchuk.com/ linkedinUrl:https://www.linkedin.com/in/garyvaynerchuk/\n",
            "\u001b[94mUser Interface Agent: \u001b[95mtransfer_to_Linkedin_Agent\u001b[0m()\n",
            "\u001b[94mLinkedin Agent: \u001b[95mprofile_info\u001b[0m()\n",
            "\u001b[94mLinkedin Agent: \u001b[95mtransfer_to_SEO_Agent\u001b[0m()\n",
            "LinkedIn Agent called......\n",
            "Retreiving Last linkedin Post\n",
            "Too many people are greatly underestimating the power of kindness.\n",
            "\n",
            "Why? I think it’s because people have this idea that being nice somehow makes you weak.\n",
            "\n",
            "They’re afraid that if they don’t bring down the hammer, people won’t respect them or they’ll get taken advantage of.\n",
            "\n",
            "I want to change that idea.\n",
            "\n",
            "Candor is not an excuse not to be kind…and being kind doesn’t prevent you from being an effective leader.\n",
            "{'firstName': 'Gary', 'lastName': 'Vaynerchuk', 'job_title': 'Chairman of VaynerX, CEO of VaynerMedia', 'job_company': 'VaynerX ', 'last_linkedin_post': 'Too many people are greatly underestimating the power of kindness.\\n\\nWhy? I think it’s because people have this idea that being nice somehow makes you weak.\\n\\nThey’re afraid that if they don’t bring down the hammer, people won’t respect them or they’ll get taken advantage of.\\n\\nI want to change that idea.\\n\\nCandor is not an excuse not to be kind…and being kind doesn’t prevent you from being an effective leader.'}\n",
            "\u001b[94mSEO Agent: \u001b[95mget_SEO_data\u001b[0m()\n",
            "SEO Agent called......\n",
            "{'traffic_history': 'For date 2024-09-01: organic traffic was 21287, and for date 2024-10-01: organic traffic was 19402', 'website_data': 'Domain Rating: 81, URL Rating: 42, Backlinks: 98856, Referring Domains: 12245, Dofollow Backlinks: 84, Dofollow Referring Domains: 86'}\n",
            "### SEO Analysis Report:\n",
            "\n",
            "#### Traffic History:\n",
            "- The organic traffic on the website has decreased from 21,287 visits in September 2024 to 19,402 visits in October 2024. This decline indicates a potential loss in search visibility or user engagement.\n",
            "- To address this drop, conduct a thorough analysis of keyword performance, on-page SEO elements, and user experience factors that might have impacted organic traffic.\n",
            "- Implement content optimization strategies, target long-tail keywords, and improve website speed and mobile responsiveness to attract more organic traffic.\n",
            "\n",
            "#### Domain and URL Rating:\n",
            "- The website has a strong Domain Rating of 81, indicating authority in the industry. However, the URL Rating of 42 suggests room for improvement in individual page rankings.\n",
            "- Focus on creating high-quality, relevant content targeting specific keywords to boost the URL rating and improve overall search visibility.\n",
            "- Implement internal linking strategies to distribute link equity across pages and enhance the authority of key landing pages.\n",
            "\n",
            "#### Backlink Profile:\n",
            "- The website boasts a considerable number of backlinks (98,856) and referring domains (12,245), showcasing a robust backlink profile.\n",
            "- The presence of 84 dofollow backlinks and 86 dofollow referring domains indicates a good balance of quality backlinks.\n",
            "- To further enhance the backlink profile, seek opportunities for guest posting, influencer collaborations, and outreach campaigns to acquire authoritative backlinks from reputable websites.\n",
            "- Monitor backlink growth, disavow toxic links, and regularly audit the backlink profile to maintain a healthy link profile.\n",
            "\n",
            "### Recommendations:\n",
            "1. Conduct a comprehensive SEO audit to identify technical issues affecting organic search visibility.\n",
            "2. Develop a content strategy focused on creating high-quality, engaging content targeting relevant keywords.\n",
            "3. Optimize on-page elements such as meta tags, headings, and image alt text for improved keyword targeting.\n",
            "4. Enhance the user experience by improving site speed, mobile-friendliness, and navigation.\n",
            "5. Continuously monitor and analyze organic traffic metrics to track the impact of SEO efforts and adjust strategies accordingly.\n",
            "\n",
            "By implementing these recommendations and leveraging the existing strengths of the website, you can improve organic search visibility, increase traffic, and ultimately enhance the overall SEO performance.\n",
            "\u001b[94mSEO Agent: \u001b[95mtransfer_to_Email_writing_Agent\u001b[0m()\n",
            "\u001b[94mEmail Writing Agent: \u001b[95mcompose_email_body\u001b[0m()\n",
            "Email Writing Agent called\n",
            "Hi Gary,\n",
            "\n",
            "I was inspired by your recent LinkedIn post on the power of kindness in leadership. Just as leading with kindness can drive positive results, enhancing your website's SEO can significantly impact your online presence and visibility.\n",
            "\n",
            "Based on our SEO analysis report, we've identified some key areas for improvement:\n",
            "\n",
            "- A decrease in organic traffic from 21,287 visits in September to 19,402 visits in October suggests a need to analyze keyword performance and enhance user experience factors.\n",
            "- While your website boasts a strong Domain Rating of 81, the URL Rating of 42 indicates room for improvement in individual page rankings.\n",
            "- Although your backlink profile is robust, focusing on acquiring authoritative backlinks can further enhance your visibility.\n",
            "\n",
            "We at Webbografi offer a complimentary SEO audit tailored to your website's needs. Our audit will provide detailed insights and a step-by-step plan to address these issues, ultimately boosting your search rankings and overall website performance.\n",
            "\n",
            "Let's work together to unlock the full potential of your online presence.\n",
            "\n",
            "Looking forward to connecting with you soon.\n",
            "\n",
            "Warm regards,\n",
            "\n",
            "[Your Name]\n",
            "SEO Specialist\n",
            "Webbografi\n",
            "\u001b[94mEmail Writing Agent: \u001b[95msend_email\u001b[0m()\n",
            "Subject: Enhancing Your Online Presence with SEO Optimization\n",
            "Email sent successfully!\n",
            "\u001b[94mEmail Writing Agent:\u001b[0m The email has been sent successfully to sasmitshashwat@outlook.com, offering a complimentary SEO audit tailored to Gary Vaynerchuk's website needs.\n"
          ]
        }
      ],
      "source": [
        "from swarm.repl import run_demo_loop\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the demo loop with the user interface agent\n",
        "    run_demo_loop(user_interface_agent, stream=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
